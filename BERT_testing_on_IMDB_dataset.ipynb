{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saichandu47/BERT_testing_on_IMDB_dataset/blob/main/BERT_testing_on_IMDB_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Br5scP26flwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VK04UfwAO0ky"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "nQqQKo2LPVeN",
        "outputId": "ca3c3ee2-4610-4dc8-fe5c-33d1442ecab4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-99593111-2486-4de7-9d89-8e64f2dba660\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-99593111-2486-4de7-9d89-8e64f2dba660\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"pattipatisaichandu\",\"key\":\"8d0cd73bd381a7642b129f736f4a9f67\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dOKJGwoFPhld"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pULR80QEPo-B"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C8iFn1lfP9me"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bpbSib3NP_sB",
        "outputId": "a491536a-6aad-44a0-c05d-8232bcc462a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/atulanandjha/imdb-50k-movie-reviews-test-your-bert\n",
            "License(s): GNU Lesser General Public License 3.0\n",
            "Downloading imdb-50k-movie-reviews-test-your-bert.zip to /content\n",
            "  0% 0.00/25.7M [00:00<?, ?B/s]\n",
            "100% 25.7M/25.7M [00:00<00:00, 938MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d atulanandjha/imdb-50k-movie-reviews-test-your-bert"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "pxEIRufXZfW_"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SsPaMjMpZfXA"
      },
      "cell_type": "markdown",
      "source": [
        "**Disclaimer :** Before, we go any further, Let me clear that You would need **GPU** and **Internet**- toggle turned **ON** (install external libraries) to succesfully run this kernel."
      ]
    },
    {
      "metadata": {
        "id": "NE_xLeAdZfXA"
      },
      "cell_type": "markdown",
      "source": [
        "![Begin](https://pbs.twimg.com/tweet_video_thumb/ECvtpBRXoAIpyUv.jpg)\n",
        "\n",
        "Img source : https://pbs.twimg.com/tweet_video_thumb/ECvtpBRXoAIpyUv.jpg"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ILspT8NFZfXB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5000eac9-12c8-4439-82ae-d42d924bb450"
      },
      "cell_type": "code",
      "source": [
        "# pytorch_pretained_bert already available in kaggle conda env.\n",
        "!pip install pytorch-nlp"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-nlp\n",
            "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-nlp) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pytorch-nlp) (4.67.1)\n",
            "Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uZujl6BUZfXB"
      },
      "cell_type": "markdown",
      "source": [
        "**Note :** uncomment the code line in above cell; you are running this notebook locally, and would need pytorch-nlp library.Here, it is pre-installed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SyOTUv2-ePrs",
        "outputId": "3ac434ef-341c-496f-cc76-98b64ef82d9b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl.metadata (86 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.0.2)\n",
            "Collecting boto3 (from pytorch-pretrained-bert)\n",
            "  Downloading boto3-1.40.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=0.4.1->pytorch-pretrained-bert)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n",
            "Collecting botocore<1.41.0,>=1.40.8 (from boto3->pytorch-pretrained-bert)\n",
            "  Downloading botocore-1.40.8-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->pytorch-pretrained-bert)\n",
            "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.41.0,>=1.40.8->boto3->pytorch-pretrained-bert) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.8->boto3->pytorch-pretrained-bert) (1.17.0)\n",
            "Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.40.8-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.8-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed boto3-1.40.8 botocore-1.40.8 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 pytorch-pretrained-bert-0.6.2 s3transfer-0.13.1\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "roh9Y45wZfXB"
      },
      "cell_type": "markdown",
      "source": [
        "### importing necessaries libraries..."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7EHjTrIAZfXB"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertModel\n",
        "from torch import nn\n",
        "# from torchnlp.datasets import imdb_dataset      # --> We are using our own uploaded dataset.\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKhrE9GTZfXB"
      },
      "cell_type": "markdown",
      "source": [
        "### Initializing seed values to stabilize the outcomes."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "onDvYIpjZfXC"
      },
      "cell_type": "code",
      "source": [
        "rn.seed(321)\n",
        "np.random.seed(321)\n",
        "torch.manual_seed(321)\n",
        "torch.cuda.manual_seed(321)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TMxwDj41ZfXC"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EPIgWm2PQFOx",
        "outputId": "be9f5840-c0f0-4b96-a20a-8df577a77a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  imdb-50k-movie-reviews-test-your-bert.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip imdb-50k-movie-reviews-test-your-bert.zip"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IZx2nSnUZfXC"
      },
      "cell_type": "code",
      "source": [
        "path = '/content/imdb-50k-movie-reviews-test-your-bert.zip'\n",
        "\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bE4kmjgDZfXC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "36ded000-2fb5-4361-f6fb-a7421ac2a20b"
      },
      "cell_type": "code",
      "source": [
        "# experimenting here with a sample of dataset, to avoid memory overflow.\n",
        "train_data = train_data[:2000]\n",
        "test_data = test_data[:500]\n",
        "\n",
        "train_data = train_data.to_dict(orient='records')\n",
        "test_data = test_data.to_dict(orient='records')\n",
        "type(train_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "xbbGSq2vZfXD"
      },
      "cell_type": "markdown",
      "source": [
        "### Mapping sentences with their Labels..."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JiEL6tUjZfXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1e005405-f3b3-4890-f8f9-64fae0d3689d"
      },
      "cell_type": "code",
      "source": [
        "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n",
        "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n",
        "\n",
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2000, 500, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "yRVwufcdZfXD"
      },
      "cell_type": "markdown",
      "source": [
        "#### visualizing one of the sentences from train set"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "B6T3MoIdZfXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "177ddbe5-730e-47d6-d2d9-d65fdb5a4e86"
      },
      "cell_type": "code",
      "source": [
        "train_texts[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Now, I won't deny that when I purchased this off eBay, I had high expectations. This was an incredible out-of-print work from the master of comedy that I so enjoy. However, I was soon to be disappointed. Apologies to those who enjoyed it, but I just found the Compleat Al to be very difficult to watch. I got a few smiles, sure, but the majority of the funny came from the music videos (which I've got on DVD) and the rest was basically filler. You could tell that this was not Al's greatest video achievement (that honor goes to UHF). Honestly, I doubt if this will ever make the jump to DVD, so if you're an ultra-hardcore Al fan and just HAVE to own everything, buy the tape off eBay. Just don't pay too much for it.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Ue_5J--rZfXD"
      },
      "cell_type": "markdown",
      "source": [
        "## visualizing sentences lengths"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "63itf1fJZfXE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "0b06b816-080a-4341-9eba-c2fdfc316761"
      },
      "cell_type": "code",
      "source": [
        "sentences = [len(sent) for sent in train_texts]\n",
        "\n",
        "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
        "plt.bar(range(1,2001), sentences, color = ['red'])\n",
        "plt.gca().set(title='No. of characters in each sentence', xlabel='Number of sentence', ylabel='Number of Characters in each sentence');"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "EIZ9j-8jZfXE"
      },
      "cell_type": "markdown",
      "source": [
        "#### We can see that most of the sentences are around 700 - 1000 characters long, which is pretty obvious. HOwever, few sentences are shorter and few even long as 6000 characters. So, this is a good, very versatile Review Dataset."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9lAaNVfzZfXE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4337c8ee-c14a-4984-eac7-b1a04198b440"
      },
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 974570.16B/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "snl0L4UMZfXE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ef7c02f1-8723-4403-897f-b6a03cb467dc"
      },
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize('Hi my name is Atul')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', 'my', 'name', 'is', 'at', '##ul']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "9sraKhVwZfXE"
      },
      "cell_type": "markdown",
      "source": [
        "### Sample of how BERT Tokenizer works and Embeddings prepared to be fed into BERT Model.\n",
        "\n",
        "![BERT TOKENS](https://miro.medium.com/max/619/1*iJqlhZz-g6ZQJ53-rE9VvA.png)"
      ]
    },
    {
      "metadata": {
        "id": "QWvh0rlIZfXE"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing Token embeddings..."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RqTdP_I9ZfXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d5339726-cc93-4a2e-9a9e-61fa900e9b90"
      },
      "cell_type": "code",
      "source": [
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n",
        "\n",
        "len(train_tokens), len(test_tokens)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "JWEz59U_ZfXF"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing Token Ids...\n",
        "\n",
        "\n",
        "![token ids](https://jalammar.github.io/images/distilBERT/sst2-text-to-tokenized-ids-bert-example.png)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "qII1asIsZfXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "601ac904-278b-4d27-f0ed-01dcc0589843"
      },
      "cell_type": "code",
      "source": [
        "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "train_tokens_ids.shape, test_tokens_ids.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2000, 512), (500, 512))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "q6L6Hu1CZfXF"
      },
      "cell_type": "markdown",
      "source": [
        "### Many a times your Kernel will Freeze but this is just OK. Let it be. This is a heavy computing task; So,it is just a common thing to happen. I have also put Monitoring code snippets to monitor your CPU/GPU usage and also Garbage Collector to free up space.\n",
        "\n",
        "\n",
        "It is quite common to see your CPU floating above 100% and/or GPU over 100% like these screens below:\n",
        "![SNAP-1](https://i.ibb.co/3cFD5Hs/cut-1.png)\n",
        "![SNAP-2](https://i.ibb.co/G5qFRxj/cut-2.png)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "t4jhMEOLZfXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e9c45f70-72c0-4da9-d327-fa8e6416c206"
      },
      "cell_type": "code",
      "source": [
        "train_y = np.array(train_labels) == 'pos'\n",
        "test_y = np.array(test_labels) == 'pos'\n",
        "train_y.shape, test_y.shape, np.mean(train_y), np.mean(test_y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2000,), (500,), np.float64(0.4855), np.float64(0.508))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "LrteNR3cZfXF"
      },
      "cell_type": "markdown",
      "source": [
        "### Now Masking few random IDs from each sentences to remove Biasness from model."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QcG8iC-qZfXF"
      },
      "cell_type": "code",
      "source": [
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CU2uT3oZfXG"
      },
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "AArJTByMZfXG"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ACdI6w1LZfXG"
      },
      "cell_type": "code",
      "source": [
        "baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KqvH7ifnZfXG"
      },
      "cell_type": "code",
      "source": [
        "baseline_predicted = baseline_model.predict(test_texts)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yeXMabgrZfXG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "af41789b-fccf-4103-96d0-5d78622e3e1b"
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, baseline_predicted))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.84      0.83       246\n",
            "         pos       0.84      0.83      0.83       254\n",
            "\n",
            "    accuracy                           0.83       500\n",
            "   macro avg       0.83      0.83      0.83       500\n",
            "weighted avg       0.83      0.83      0.83       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lsZU_4OyZfXG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Our baseline model is working just fine and yeilding a fair enough score. Now, its time to play Dirty with the \"BERT\"."
      ]
    },
    {
      "metadata": {
        "id": "w6InrSntZfXH"
      },
      "cell_type": "markdown",
      "source": [
        "# BERT Model\n",
        "\n",
        "\n",
        "### Bidirectional Encoder Representations from Transformers. Each word here has a meaning to it and we will encounter that one by one in this article. For now, the key takeaway from this line is – **BERT is based on the Transformer architecture**."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ecM_n3TAZfXH"
      },
      "cell_type": "code",
      "source": [
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OgfDayqsZfXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ead416cd-128f-499a-e7d5-856a1b30c6f9"
      },
      "cell_type": "code",
      "source": [
        "# ensuring that the model runs on GPU, not on CPU\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "F91PJpGdZfXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e0252937-94fc-423f-f2c6-c4e54aa26616"
      },
      "cell_type": "code",
      "source": [
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Q_6YOEBsZfXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "46028b00-5b55-4b63-afbb-53fd24978052"
      },
      "cell_type": "code",
      "source": [
        "bert_clf = BertBinaryClassifier()\n",
        "bert_clf = bert_clf.cuda()     # running BERT on CUDA_GPU"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:14<00:00, 27659837.67B/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rSKXaErEZfXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b6e010b5-ffb9-46f1-ad71-b02c5e30ceb4"
      },
      "cell_type": "code",
      "source": [
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'439.065088M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "BGZqwZe9ZfXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "05a40114-7b03-4c67-becf-abfc17a66348"
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor(train_tokens_ids[:3]).to(device)\n",
        "y, pooled = bert_clf.bert(x, output_all_encoded_layers=False)\n",
        "x.shape, y.shape, pooled.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 512]), torch.Size([3, 512, 768]), torch.Size([3, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "t-cQ51CkZfXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "386cb7a7-fede-4093-df81-98b688b343e7"
      },
      "cell_type": "code",
      "source": [
        "y = bert_clf(x)\n",
        "y.cpu().detach().numpy()        # kinda Garbage Collector to free up used and cache space"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40179852],\n",
              "       [0.4417363 ],\n",
              "       [0.38996655]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wrxwkA4bZfXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fcc8a5ff-5c37-4f92-fbf8-c1a7ded10af3"
      },
      "cell_type": "code",
      "source": [
        "# Cross- checking CUDA GPU Memory to ensure GPU memory is not overflowing.\n",
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5799.899648M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-7OHUCYzZfXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6064c180-690f-48c4-da03-152d0d0d4acf"
      },
      "cell_type": "code",
      "source": [
        "y, x, pooled = None, None, None\n",
        "torch.cuda.empty_cache()     # Clearing Cache space for fresh Model run\n",
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'447.584768M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "6RWYDxjjZfXQ"
      },
      "cell_type": "markdown",
      "source": [
        "# Fine Tune BERT"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TRhBptNGZfXQ"
      },
      "cell_type": "code",
      "source": [
        "# Setting hyper-parameters\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "NwajzCCUZfXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "96285b0e-0c86-43cf-8767-b74fa7f77162"
      },
      "cell_type": "code",
      "source": [
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'447.584768M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "84c1Sw4YZfXQ"
      },
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SWJYJlq6ZfXR"
      },
      "cell_type": "code",
      "source": [
        "param_optimizer = list(bert_clf.sigmoid.named_parameters())\n",
        "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VoYuXOhIZfXR"
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(bert_clf.parameters(), lr=3e-6)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OJQBDVsUZfXR"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()   # Clearing Cache space for a fresh Model run"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zNQNLjoDZfXS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "07c9f9dc-611e-48be-e3b3-6a02eead9758"
      },
      "cell_type": "code",
      "source": [
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "\n",
        "        loss_func = nn.BCELoss()\n",
        "\n",
        "        batch_loss = loss_func(logits, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "\n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "\n",
        "\n",
        "        clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  10\n",
            "\r499/500.0 loss: 0.0282578137529199 \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vjlzWo6oZfXS"
      },
      "cell_type": "code",
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        loss_func = nn.BCELoss()\n",
        "        loss = loss_func(logits, labels)\n",
        "        numpy_logits = logits.cpu().detach().numpy()\n",
        "\n",
        "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
        "        all_logits += list(numpy_logits[:, 0])\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CUv3DuusZfXS"
      },
      "cell_type": "code",
      "source": [
        "np.mean(bert_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UlwEOZPVZfXS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4e0202a0-37d7-4703-ebfb-1e8fca87fe4c"
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(test_y, bert_predicted))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.89      0.90       246\n",
            "        True       0.89      0.91      0.90       254\n",
            "\n",
            "    accuracy                           0.90       500\n",
            "   macro avg       0.90      0.90      0.90       500\n",
            "weighted avg       0.90      0.90      0.90       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(bert_clf.state_dict(), \"bert_imdb_model.pt\")\n"
      ],
      "metadata": {
        "id": "XliBLcSyk4BK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wqi9R2T-k79T",
        "outputId": "9eee1d99-f624-4a07-e1de-27718bfb854a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.11/dist-packages (0.6.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.41.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.0.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (1.40.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2024.11.6)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: botocore<1.41.0,>=1.40.8 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (1.40.8)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "import gradio as gr\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Detect device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the BertBinaryClassifier class (same as PDF)\n",
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba\n",
        "\n",
        "# Load tokenizer (same as training)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model = BertBinaryClassifier()\n",
        "model.load_state_dict(torch.load(\"bert_imdb_model.pt\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Prediction function\n",
        "def predict_sentiment(review_text):\n",
        "    try:\n",
        "        if not review_text.strip():\n",
        "            return \"Error: Empty review text\"\n",
        "\n",
        "        # --- manual tokenization (pytorch_pretrained_bert has no encode_plus) ---\n",
        "        tokens = tokenizer.tokenize(review_text)\n",
        "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        max_len = 512\n",
        "        if len(input_ids) < max_len:\n",
        "            input_ids += [0] * (max_len - len(input_ids))\n",
        "        else:\n",
        "            input_ids = input_ids[:max_len]\n",
        "\n",
        "        attention_mask = [1 if tid != 0 else 0 for tid in input_ids]\n",
        "\n",
        "        input_ids = torch.tensor([input_ids]).to(device)\n",
        "        attention_mask = torch.tensor([attention_mask]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            proba_pos = model(input_ids, masks=attention_mask).squeeze().item()\n",
        "            proba_pos = max(0.0, min(1.0, proba_pos))  # clamp for safety\n",
        "\n",
        "        is_positive = proba_pos >= 0.5\n",
        "        label = \"Positive\" if is_positive else \"Negative\"\n",
        "        confidence = proba_pos if is_positive else (1.0 - proba_pos)\n",
        "\n",
        "        return f\"{label} ({confidence*100:.2f}% confidence)\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "# Launch Gradio app\n",
        "iface = gr.Interface(\n",
        "    fn=predict_sentiment,\n",
        "    inputs=gr.Textbox(lines=4, placeholder=\"Enter a movie review...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Movie Review Sentiment Analysis\",\n",
        "    description=\"Fine-tuned BERT on IMDB dataset using pytorch_pretrained_bert.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "i_FiBXCPk89N",
        "outputId": "1f138483-3276-4cdc-b3be-1b856bd2507a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://34d174a292ea715d67.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://34d174a292ea715d67.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert flask flask-ngrok\n",
        "# Torch is usually preinstalled on Colab; if not:\n",
        "# !pip install torch\n"
      ],
      "metadata": {
        "id": "fOsmOJKSwerJ",
        "outputId": "91c78d2a-5237-47a7-acc9-090563864cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.11/dist-packages (0.6.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.0.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (1.40.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2024.11.6)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n",
            "Requirement already satisfied: botocore<1.41.0,>=1.40.8 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (1.40.8)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.41.0,>=1.40.8->boto3->pytorch-pretrained-bert) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.8->boto3->pytorch-pretrained-bert) (1.17.0)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(bert_clf.state_dict(), \"bert_imdb_model.pt\")\n"
      ],
      "metadata": {
        "id": "Z41GaVEClBsu"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write app.py and template files\n",
        "app_py = r'''\n",
        "from flask import Flask, request, render_template\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Model class (same as your PDF)\n",
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, tokens, masks=None):\n",
        "        # note: older API returns (sequence_output, pooled_output)\n",
        "        outputs = self.bert(tokens, attention_mask=masks)\n",
        "        # outputs could be tuple or object; handle tuple\n",
        "        if isinstance(outputs, tuple):\n",
        "            pooled_output = outputs[1]\n",
        "        else:\n",
        "            pooled_output = outputs.pooler_output\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba\n",
        "\n",
        "# Load tokenizer & model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model = BertBinaryClassifier()\n",
        "model.load_state_dict(torch.load(\"bert_imdb_model.pt\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    # handle empty input\n",
        "    if not text or not text.strip():\n",
        "        return \"Error: Empty review\"\n",
        "\n",
        "    # manual tokenization for pytorch_pretrained_bert\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    max_len = 512\n",
        "    if len(input_ids) < max_len:\n",
        "        input_ids += [0] * (max_len - len(input_ids))\n",
        "    else:\n",
        "        input_ids = input_ids[:max_len]\n",
        "\n",
        "    attention_mask = [1 if tid != 0 else 0 for tid in input_ids]\n",
        "\n",
        "    input_ids = torch.tensor([input_ids]).to(device)\n",
        "    attention_mask = torch.tensor([attention_mask]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proba_pos = model(input_ids, masks=attention_mask).squeeze().item()\n",
        "        proba_pos = max(0.0, min(1.0, proba_pos))\n",
        "\n",
        "    is_pos = proba_pos >= 0.5\n",
        "    label = \"Positive\" if is_pos else \"Negative\"\n",
        "    confidence = proba_pos if is_pos else (1.0 - proba_pos)\n",
        "    return f\"{label} ({confidence*100:.2f}% confidence)\"\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def index():\n",
        "    result = \"\"\n",
        "    if request.method == 'POST':\n",
        "        text = request.form.get('review', '')\n",
        "        try:\n",
        "            result = predict_sentiment(text)\n",
        "        except Exception as e:\n",
        "            result = f\"Error: {str(e)}\"\n",
        "    return render_template('index.html', result=result)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Use flask-ngrok to expose to web when running from Colab\n",
        "    from flask_ngrok import run_with_ngrok\n",
        "    run_with_ngrok(app)\n",
        "    app.run()\n",
        "'''\n",
        "with open('app.py','w') as f:\n",
        "    f.write(app_py)\n",
        "\n",
        "html = r'''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <meta charset=\"utf-8\" />\n",
        "    <title>Movie Review Sentiment</title>\n",
        "    <style>\n",
        "      body { font-family: Arial, sans-serif; background:#121212; color:#fff; text-align:center; }\n",
        "      textarea { width:80%; height:160px; background:#1f1f1f; color:#fff; border:1px solid #333; padding:10px;}\n",
        "      .btn { padding:12px 24px; background:#ff6b2d; color:#fff; border:none; cursor:pointer; }\n",
        "      .result { margin-top:20px; font-size:18px; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Movie Review Sentiment Analysis</h1>\n",
        "    <p>Fine-tuned BERT on IMDB dataset (pytorch_pretrained_bert)</p>\n",
        "    <form method=\"POST\">\n",
        "        <textarea name=\"review\" placeholder=\"Enter review...\"></textarea><br/><br/>\n",
        "        <button class=\"btn\" type=\"submit\">Submit</button>\n",
        "    </form>\n",
        "    {% if result %}\n",
        "      <div class=\"result\"><strong>Result:</strong> {{ result }}</div>\n",
        "    {% endif %}\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "import os\n",
        "os.makedirs('templates', exist_ok=True)\n",
        "with open('templates/index.html','w') as f:\n",
        "    f.write(html)\n",
        "\n",
        "print(\"app.py and template created.\")\n"
      ],
      "metadata": {
        "id": "OjRmM41Ewwny",
        "outputId": "69845fee-1240-438f-fb71-f29b46206ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py and template created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py\n"
      ],
      "metadata": {
        "id": "ePUnUHhLwxTA",
        "outputId": "a2bf329e-822f-4f1b-a5bb-e43aa12b5a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            " * Serving Flask app 'app'\n",
            " * Debug mode: off\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Usage of ngrok requires a verified account and authtoken.\n",
            "\n",
            "Sign up for an account: https://dashboard.ngrok.com/signup\n",
            "Install your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "\n",
            "ERR_NGROK_4018\n",
            "\n",
            "Exception in thread Thread-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 494, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 996, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 325, in connect\n",
            "    self.sock = self._new_conn()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 213, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7e7f15ec5310>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n",
            "    resp = conn.urlopen(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
            "    retries = retries.increment(\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\", line 519, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e7f15ec5310>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1401, in run\n",
            "    self.function(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
            "    ngrok_address = _run_ngrok()\n",
            "                    ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
            "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 73, in get\n",
            "    return request(\"get\", url, params=params, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 700, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e7f15ec5310>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oDAJeoKUw3HP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}